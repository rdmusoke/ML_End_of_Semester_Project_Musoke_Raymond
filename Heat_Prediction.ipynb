{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5487900d-36b2-49b3-8559-dc036a775a8d",
   "metadata": {},
   "source": [
    "A Comparative Machine Learning Approach for Interpretable Heart Disease Prediction in Low-Resource Settings_ By Raymond Musoke"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08e59f1",
   "metadata": {},
   "source": [
    "Importing the Necessary Project Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a455472-4aaa-474b-913c-76a26507dc83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix\n",
    "from sklearn.impute import SimpleImputer\n",
    "import shap\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Heart Disease Prediction Project...\")\n",
    "print(\"Loading and preparing data...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce0d2b9",
   "metadata": {},
   "source": [
    "Loading the Heart Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0be7289-03d2-4b48-bd9f-8c7e4cca0bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Heart dataset\n",
    "# I'm Using the Cleveland Heart Disease dataset from UCI\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/processed.cleveland.data\"\n",
    "column_names = [\n",
    "    'age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', \n",
    "    'thalach', 'exang', 'oldpeak', 'slope', 'ca', 'thal', 'target'\n",
    "]\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(url, names=column_names, na_values='?')\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(\"\\nFirst few rows of the dataset:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef4cff1b-5434-4761-b5f9-5b054ab6d94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Exploration and Understanding\n",
    "print(\"= DATA EXPLORATION =\")\n",
    "print(\"\\nDataset Info:\")\n",
    "print(df.info())\n",
    "print(\"\\nMissing Values:\")\n",
    "print(df.isnull().sum())\n",
    "print(\"\\nBasic Statistics:\")\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d87a28d",
   "metadata": {},
   "source": [
    "Handling the Missing Values in the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde83d6d-a78f-476c-b4cb-c96a951993e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing values as mentioned in preprocessing objective\n",
    "print(\"DATA PREPROCESSING...\")\n",
    "\n",
    "# Check for missing values\n",
    "print(\"Missing values before preprocessing:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Handle missing values using mean imputation for numerical features\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "df[['ca', 'thal']] = imputer.fit_transform(df[['ca', 'thal']])\n",
    "\n",
    "print(\"\\nMissing values after preprocessing:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Convert target to binary (0: no disease, 1: disease) as mentioned in clinical focus\n",
    "df['target'] = (df['target'] > 0).astype(int)\n",
    "\n",
    "print(f\"\\nTarget distribution:\\n{df['target'].value_counts()}\")\n",
    "print(f\"Disease prevalence: {df['target'].mean():.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33708efc",
   "metadata": {},
   "source": [
    "Describing the identified features from the Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c569ea-a906-42cc-9b14-1ae36f668bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature description for interpretability\n",
    "feature_descriptions = {\n",
    "    'age': 'Age in years',\n",
    "    'sex': 'Sex (1 = male; 0 = female)',\n",
    "    'cp': 'Chest pain type (0: typical angina, 1: atypical angina, 2: non-anginal pain, 3: asymptomatic)',\n",
    "    'trestbps': 'Resting blood pressure (mm Hg)',\n",
    "    'chol': 'Serum cholesterol (mg/dl)',\n",
    "    'fbs': 'Fasting blood sugar > 120 mg/dl (1 = true; 0 = false)',\n",
    "    'restecg': 'Resting electrocardiographic results',\n",
    "    'thalach': 'Maximum heart rate achieved',\n",
    "    'exang': 'Exercise induced angina (1 = yes; 0 = no)',\n",
    "    'oldpeak': 'ST depression induced by exercise relative to rest',\n",
    "    'slope': 'Slope of the peak exercise ST segment',\n",
    "    'ca': 'Number of major vessels (0-3) colored by fluoroscopy',\n",
    "    'thal': 'Thalassemia (3 = normal; 6 = fixed defect; 7 = reversible defect)'\n",
    "}\n",
    "\n",
    "print(\"FEATURE DESCRIPTIONS...\")\n",
    "for feature, description in feature_descriptions.items():\n",
    "    print(f\"{feature}: {description}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba23d5c7",
   "metadata": {},
   "source": [
    "Performing a Data Analysis with the Identified Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02baef4-b941-4ed3-81fd-4e58dc7f58ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploratory Data Analysis\n",
    "print(\"EXPLORATORY DATA ANALYSIS...\")\n",
    "\n",
    "plt.figure(figsize=(15, 12))\n",
    "\n",
    "# Plot 1: Target distribution\n",
    "plt.subplot(2, 3, 1)\n",
    "df['target'].value_counts().plot(kind='bar', color=['skyblue', 'lightcoral'])\n",
    "plt.title('Heart Disease Distribution')\n",
    "plt.xlabel('Heart Disease (0: No, 1: Yes)')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "# Plot 2: Age distribution by target\n",
    "plt.subplot(2, 3, 2)\n",
    "sns.histplot(data=df, x='age', hue='target', bins=15, alpha=0.6)\n",
    "plt.title('Age Distribution by Heart Disease')\n",
    "\n",
    "# Plot 3: Cholesterol distribution\n",
    "plt.subplot(2, 3, 3)\n",
    "sns.histplot(data=df, x='chol', hue='target', bins=15, alpha=0.6)\n",
    "plt.title('Cholesterol Distribution by Heart Disease')\n",
    "\n",
    "# Plot 4: Maximum heart rate distribution\n",
    "plt.subplot(2, 3, 4)\n",
    "sns.histplot(data=df, x='thalach', hue='target', bins=15, alpha=0.6)\n",
    "plt.title('Max Heart Rate Distribution by Heart Disease')\n",
    "\n",
    "# Plot 5: Correlation heatmap\n",
    "plt.subplot(2, 3, 5)\n",
    "correlation_matrix = df.corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, fmt='.2f')\n",
    "plt.title('Feature Correlation Heatmap')\n",
    "\n",
    "# Plot 6: Chest pain type vs heart disease\n",
    "plt.subplot(2, 3, 6)\n",
    "pd.crosstab(df['cp'], df['target']).plot(kind='bar', alpha=0.8)\n",
    "plt.title('Chest Pain Type vs Heart Disease')\n",
    "plt.xlabel('Chest Pain Type')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2177d4ec",
   "metadata": {},
   "source": [
    "Splitting the Data, Training and Processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40b8712-9d8d-4b4b-983a-3c4a7d7a3282",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Implementation and Training\n",
    "print(\"MODEL IMPLEMENTATION AND TRAINING...\")\n",
    "\n",
    "# Initialize models\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(random_state=42),\n",
    "    'K-Nearest Neighbors': KNeighborsClassifier(),\n",
    "    'Random Forest': RandomForestClassifier(random_state=42)\n",
    "}\n",
    "\n",
    "# Hyperparameter tuning for better performance\n",
    "param_grids = {\n",
    "    'Logistic Regression': {\n",
    "        'C': [0.1, 1, 10],\n",
    "        'solver': ['liblinear', 'lbfgs']\n",
    "    },\n",
    "    'K-Nearest Neighbors': {\n",
    "        'n_neighbors': [3, 5, 7, 9],\n",
    "        'weights': ['uniform', 'distance']\n",
    "    },\n",
    "    'Random Forest': {\n",
    "        'n_estimators': [100, 200],\n",
    "        'max_depth': [None, 10, 20],\n",
    "        'min_samples_split': [2, 5]\n",
    "    }\n",
    "}\n",
    "# Data Preprocessing and Feature Scaling\n",
    "print(\"DATA PREPROCESSING AND FEATURE SCALING...\")\n",
    "\n",
    "# Split data into features and target\n",
    "X = df.drop('target', axis=1)\n",
    "y = df['target']\n",
    "\n",
    "print(f\"Features shape: {X.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "print(f\"Training set: {X_train.shape}, {y_train.shape}\")\n",
    "print(f\"Testing set: {X_test.shape}, {y_test.shape}\")\n",
    "\n",
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"Feature scaling completed successfully!\")\n",
    "print(f\"Scaled training set shape: {X_train_scaled.shape}\")\n",
    "print(f\"Scaled testing set shape: {X_test_scaled.shape}\")\n",
    "# Train and tune models\n",
    "trained_models = {}\n",
    "model_performance = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n--- Training {name} ---\")\n",
    "    \n",
    "    # Perform grid search\n",
    "    grid_search = GridSearchCV(model, param_grids[name], cv=5, scoring='f1', n_jobs=-1)\n",
    "    grid_search.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Store best model\n",
    "    trained_models[name] = grid_search.best_estimator_\n",
    "    \n",
    "    print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "    print(f\"Best CV score: {grid_search.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7155b8f",
   "metadata": {},
   "source": [
    "Performing a Model Evaluaton "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0b8564-788a-43ef-ad53-234d58d22920",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Evaluation\n",
    "print(\" MODEL EVALUATION...\")\n",
    "\n",
    "def evaluate_model(model, X_test, y_test, model_name):\n",
    "    \"\"\"Comprehensive model evaluation\"\"\"\n",
    "    # Making predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    \n",
    "    # Store performance\n",
    "    performance = {\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1-Score': f1\n",
    "    }\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"\\n{model_name} Performance:\")\n",
    "    print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall:    {recall:.4f}\")\n",
    "    print(f\"F1-Score:  {f1:.4f}\")\n",
    "    \n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=['No Disease', 'Disease'],\n",
    "                yticklabels=['No Disease', 'Disease'])\n",
    "    plt.title(f'Confusion Matrix - {model_name}')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.show()\n",
    "    \n",
    "    return performance\n",
    "\n",
    "# Evaluate all models\n",
    "for name, model in trained_models.items():\n",
    "    model_performance[name] = evaluate_model(model, X_test_scaled, y_test, name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e0cdb8",
   "metadata": {},
   "source": [
    "Performing a Comaparative Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb32bff-2f45-4f86-a653-8282221acfb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparative Analysis\n",
    "print(\" COMPARATIVE ANALYSIS...\")\n",
    "\n",
    "# Create performance comparison dataframe\n",
    "performance_df = pd.DataFrame(model_performance).T\n",
    "print(\"\\nPerformance Comparison:\")\n",
    "print(performance_df.round(4))\n",
    "\n",
    "# Visual comparison\n",
    "plt.figure(figsize=(12, 8))\n",
    "metrics = ['Accuracy', 'Precision', 'Recall', 'F1-Score']\n",
    "x_pos = np.arange(len(metrics))\n",
    "\n",
    "for i, model in enumerate(performance_df.index):\n",
    "    plt.bar(x_pos + i*0.2, performance_df.loc[model, metrics], \n",
    "            width=0.2, label=model, alpha=0.8)\n",
    "\n",
    "plt.xlabel('Metrics')\n",
    "plt.ylabel('Score')\n",
    "plt.title('Comparative Model Performance')\n",
    "plt.xticks(x_pos + 0.2, metrics)\n",
    "plt.legend()\n",
    "plt.ylim(0, 1)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# Identify best model based on F1-Score (balanced metric)\n",
    "best_model_name = performance_df['F1-Score'].idxmax()\n",
    "best_model = trained_models[best_model_name]\n",
    "print(f\"\\nBest Model: {best_model_name} (F1-Score: {performance_df.loc[best_model_name, 'F1-Score']:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885875e8",
   "metadata": {},
   "source": [
    "Interpretation of the Model with SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c03913b-898b-4671-ba39-45d5af4debaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Interpretability with SHAP\n",
    "print(\"MODEL INTERPRETABILITY WITH SHAP...\")\n",
    "\n",
    "# Use the best model for SHAP analysis\n",
    "print(f\"Performing SHAP analysis for {best_model_name}...\")\n",
    "\n",
    "if best_model_name == 'Logistic Regression':\n",
    "    # For linear models, use linear explainer\n",
    "    explainer = shap.LinearExplainer(best_model, X_train_scaled)\n",
    "    shap_values = explainer.shap_values(X_test_scaled)\n",
    "    \n",
    "elif best_model_name == 'Random Forest':\n",
    "    # For tree-based models\n",
    "    explainer = shap.TreeExplainer(best_model)\n",
    "    shap_values = explainer.shap_values(X_test_scaled)\n",
    "    if isinstance(shap_values, list):\n",
    "        shap_values = shap_values[1]  # For classification, take class 1\n",
    "    \n",
    "else:  # KNN - use KernelExplainer\n",
    "    def predict_proba_wrapper(X):\n",
    "        return best_model.predict_proba(X)\n",
    "    \n",
    "    explainer = shap.KernelExplainer(predict_proba_wrapper, X_train_scaled[:100])\n",
    "    shap_values = explainer.shap_values(X_test_scaled[:50])\n",
    "\n",
    "# Create SHAP summary plot\n",
    "plt.figure(figsize=(10, 8))\n",
    "if best_model_name != 'K-Nearest Neighbors':\n",
    "    shap.summary_plot(shap_values, X_test_scaled, feature_names=X.columns, show=False)\n",
    "else:\n",
    "    shap.summary_plot(shap_values[:,:,1], X_test_scaled[:50], feature_names=X.columns, show=False)\n",
    "plt.title(f'SHAP Summary Plot - {best_model_name}')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5a04c2",
   "metadata": {},
   "source": [
    "Analysing Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748d9f23-a66a-4ed8-9bfc-2cec4b685489",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed Feature Importance Analysis\n",
    "print(\"DETAILED FEATURE IMPORTANCE ANALYSIS..\")\n",
    "\n",
    "# Get feature importance based on model type\n",
    "if best_model_name == 'Logistic Regression':\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'feature': X.columns,\n",
    "        'importance': np.abs(best_model.coef_[0])\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "elif best_model_name == 'Random Forest':\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'feature': X.columns,\n",
    "        'importance': best_model.feature_importances_\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "else:  # For KNN, use mean absolute SHAP values\n",
    "    if best_model_name == 'K-Nearest Neighbors':\n",
    "        feature_importance = pd.DataFrame({\n",
    "            'feature': X.columns,\n",
    "            'importance': np.mean(np.abs(shap_values[:,:,1]), axis=0)\n",
    "        }).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"Feature Importance Ranking:\")\n",
    "print(feature_importance)\n",
    "\n",
    "# Plot feature importance\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(data=feature_importance, x='importance', y='feature', palette='viridis')\n",
    "plt.title(f'Feature Importance - {best_model_name}')\n",
    "plt.xlabel('Importance')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a67bbf7",
   "metadata": {},
   "source": [
    "The Clinical Application and Intrepretaion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b086e2-3228-49ac-8dbc-58a4e685bb54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clinical Application and Interpretation\n",
    "print(\"CLINICAL APPLICATION AND INTERPRETATION...\")\n",
    "\n",
    "# Analyze top features for clinical relevance\n",
    "top_features = feature_importance.head(5)['feature'].tolist()\n",
    "print(f\"\\nTop 5 Most Important Clinical Features:\")\n",
    "for i, feature in enumerate(top_features, 1):\n",
    "    description = feature_descriptions.get(feature, 'No description available')\n",
    "    print(f\"{i}. {feature}: {description}\")\n",
    "\n",
    "# Create a simple risk assessment example\n",
    "print(\"\\nCLINICAL RISK ASSESSMENT EXAMPLE...\")\n",
    "sample_patient = X_test_scaled[0:1]\n",
    "sample_original = X_test.iloc[0:1]\n",
    "\n",
    "print(\"Sample Patient Clinical Data:\")\n",
    "for feature in top_features:\n",
    "    original_value = sample_original[feature].values[0]\n",
    "    print(f\"  {feature}: {original_value}\")\n",
    "\n",
    "prediction = best_model.predict(sample_patient)[0]\n",
    "probability = best_model.predict_proba(sample_patient)[0][1]\n",
    "\n",
    "print(f\"\\nRisk Assessment:\")\n",
    "print(f\"  Heart Disease Prediction: {'HIGH RISK' if prediction == 1 else 'LOW RISK'}\")\n",
    "print(f\"  Probability of Disease: {probability:.1%}\")\n",
    "\n",
    "if probability > 0.7:\n",
    "    print(\"  Clinical Action: Recommend further diagnostic tests and consultation\")\n",
    "elif probability > 0.3:\n",
    "    print(\"  Clinical Action: Monitor closely and consider lifestyle changes\")\n",
    "else:\n",
    "    print(\"  Clinical Action: Low risk - routine monitoring recommended\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd45b9d",
   "metadata": {},
   "source": [
    "Summary and Recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39cd8cf4-1b36-4008-b632-05fd73f9df1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Summary and Recommendations\n",
    "print(\"=== PROJECT SUMMARY AND CONCLUSIONS ===\")\n",
    "\n",
    "print(\"\\nKEY FINDINGS:\")\n",
    "print(f\"1. Best Performing Model: {best_model_name}\")\n",
    "print(f\"2. Best F1-Score: {performance_df.loc[best_model_name, 'F1-Score']:.4f}\")\n",
    "print(f\"3. Best Recall: {performance_df.loc[best_model_name, 'Recall']:.4f}\")\n",
    "\n",
    "print(\"\\nCLINICALLY SIGNIFICANT FEATURES:\")\n",
    "for feature in top_features:\n",
    "    importance = feature_importance[feature_importance['feature'] == feature]['importance'].values[0]\n",
    "    print(f\"  - {feature} (importance: {importance:.3f})\")\n",
    "\n",
    "print(\"\\nMODEL SUITABILITY FOR LOW-RESOURCE SETTINGS:\")\n",
    "print(\"✓ Uses readily available clinical parameters\")\n",
    "print(\"✓ Provides interpretable predictions\")\n",
    "print(\"✓ Balanced performance across key medical metrics\")\n",
    "print(\"✓ Identifies high-risk patients effectively\")\n",
    "\n",
    "print(\"\\nRECOMMENDATIONS FOR CLINICAL DEPLOYMENT:\")\n",
    "print(\"1. Use as a screening tool to identify high-risk patients\")\n",
    "print(\"2. Combine model predictions with clinical judgment\")\n",
    "print(\"3. Focus on patients with multiple risk factors\")\n",
    "print(\"4. Regular model validation with local patient data here in Uganda\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
